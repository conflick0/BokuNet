{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory  # pip install tf-nightly\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \",\n",
    "      len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./augment_dataset/sdd\"\n",
    "\n",
    "TRAIN_DATASET_DIR = DATASET_DIR + '/train'\n",
    "\n",
    "TEST_DATASET_DIR = DATASET_DIR + '/test'\n",
    "\n",
    "IMG_SIZE = (150, 150)\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32458 files belonging to 120 classes.\n",
      "Found 8222 files belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# build train dataset\n",
    "train_ds = image_dataset_from_directory(directory=TRAIN_DATASET_DIR,\n",
    "                                        labels='inferred',\n",
    "                                        label_mode='categorical',\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        image_size=IMG_SIZE)\n",
    "\n",
    "#build test dataset\n",
    "test_ds = image_dataset_from_directory(directory=TEST_DATASET_DIR,\n",
    "                                       labels='inferred',\n",
    "                                       label_mode='categorical',\n",
    "                                       shuffle=False,\n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_imgs.shape:  (128, 150, 150, 3)\n",
      "train_labels.shape:  (128, 120)\n",
      "['n02097209-standard_schnauzer', 'n02093647-Bedlington_terrier', 'n02094258-Norwich_terrier', 'n02097298-Scotch_terrier', 'n02099267-flat-coated_retriever', 'n02107908-Appenzeller', 'n02108915-French_bulldog', 'n02089078-black-and-tan_coonhound', 'n02105056-groenendael', 'n02088364-beagle', 'n02088632-bluetick', 'n02099429-curly-coated_retriever', 'n02097130-giant_schnauzer', 'n02091134-whippet', 'n02094433-Yorkshire_terrier', 'n02093754-Border_terrier', 'n02111889-Samoyed', 'n02094258-Norwich_terrier', 'n02097658-silky_terrier', 'n02089867-Walker_hound', 'n02095314-wire-haired_fox_terrier', 'n02099712-Labrador_retriever', 'n02093859-Kerry_blue_terrier', 'n02111500-Great_Pyrenees', 'n02090721-Irish_wolfhound', 'n02098413-Lhasa', 'n02106030-collie', 'n02099712-Labrador_retriever', 'n02086910-papillon', 'n02100735-English_setter', 'n02088466-bloodhound', 'n02091467-Norwegian_elkhound', 'n02109525-Saint_Bernard', 'n02096437-Dandie_Dinmont', 'n02092002-Scottish_deerhound', 'n02095314-wire-haired_fox_terrier', 'n02089078-black-and-tan_coonhound', 'n02108422-bull_mastiff', 'n02109525-Saint_Bernard', 'n02116738-African_hunting_dog', 'n02111889-Samoyed', 'n02095314-wire-haired_fox_terrier', 'n02105505-komondor', 'n02088466-bloodhound', 'n02113978-Mexican_hairless', 'n02109961-Eskimo_dog', 'n02086079-Pekinese', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02085936-Maltese_dog', 'n02100583-vizsla', 'n02098105-soft-coated_wheaten_terrier', 'n02105162-malinois', 'n02089973-English_foxhound', 'n02096177-cairn', 'n02108000-EntleBucher', 'n02088632-bluetick', 'n02088094-Afghan_hound', 'n02101388-Brittany_spaniel', 'n02096294-Australian_terrier', 'n02087394-Rhodesian_ridgeback', 'n02093428-American_Staffordshire_terrier', 'n02085936-Maltese_dog', 'n02085620-Chihuahua', 'n02109047-Great_Dane', 'n02097130-giant_schnauzer', 'n02113186-Cardigan', 'n02110806-basenji', 'n02100583-vizsla', 'n02113799-standard_poodle', 'n02108422-bull_mastiff', 'n02108089-boxer', 'n02088632-bluetick', 'n02094258-Norwich_terrier', 'n02097658-silky_terrier', 'n02086240-Shih-Tzu', 'n02102040-English_springer', 'n02102480-Sussex_spaniel', 'n02107683-Bernese_mountain_dog', 'n02112137-chow', 'n02108000-EntleBucher', 'n02108551-Tibetan_mastiff', 'n02107908-Appenzeller', 'n02100735-English_setter', 'n02110806-basenji', 'n02107683-Bernese_mountain_dog', 'n02111500-Great_Pyrenees', 'n02101556-clumber', 'n02098286-West_Highland_white_terrier', 'n02096051-Airedale', 'n02092339-Weimaraner', 'n02091032-Italian_greyhound', 'n02106030-collie', 'n02089078-black-and-tan_coonhound', 'n02102318-cocker_spaniel', 'n02113624-toy_poodle', 'n02098105-soft-coated_wheaten_terrier', 'n02088632-bluetick', 'n02113978-Mexican_hairless', 'n02096437-Dandie_Dinmont', 'n02113978-Mexican_hairless', 'n02097658-silky_terrier', 'n02089867-Walker_hound', 'n02086646-Blenheim_spaniel', 'n02088364-beagle', 'n02102973-Irish_water_spaniel', 'n02110627-affenpinscher', 'n02108422-bull_mastiff', 'n02098105-soft-coated_wheaten_terrier', 'n02113186-Cardigan', 'n02088094-Afghan_hound', 'n02105251-briard', 'n02097209-standard_schnauzer', 'n02106166-Border_collie', 'n02092002-Scottish_deerhound', 'n02097298-Scotch_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02108000-EntleBucher', 'n02091831-Saluki', 'n02107574-Greater_Swiss_Mountain_dog', 'n02105162-malinois', 'n02108089-boxer', 'n02088632-bluetick', 'n02110185-Siberian_husky', 'n02095570-Lakeland_terrier', 'n02107574-Greater_Swiss_Mountain_dog', 'n02085782-Japanese_spaniel', 'n02105855-Shetland_sheepdog']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 128 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show train batch\n",
    "train_imgs, train_labels = next(iter(train_ds))\n",
    "\n",
    "print(\"train_imgs.shape: \", train_imgs.shape)\n",
    "print(\"train_labels.shape: \", train_labels.shape)\n",
    "\n",
    "plt.figure(num=BATCH_SIZE, figsize=(16, 16))\n",
    "for i, img in enumerate(train_imgs):\n",
    "    plt.subplot(1, BATCH_SIZE, i + 1)\n",
    "    plt.imshow(tf.make_ndarray(tf.make_tensor_proto(img)).astype('uint8'))\n",
    "\n",
    "labels = [\n",
    "    train_ds.class_names[np.where(label == 1)[0][0]] for label in train_labels\n",
    "]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "traing dataset size: 254\n",
      "test dataset size: 65\n",
      "\n",
      "class names:\n",
      " ['n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog', 'n02086079-Pekinese', 'n02086240-Shih-Tzu', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02088094-Afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-Walker_hound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091032-Italian_greyhound', 'n02091134-whippet', 'n02091244-Ibizan_hound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02093428-American_Staffordshire_terrier', 'n02093647-Bedlington_terrier', 'n02093754-Border_terrier', 'n02093859-Kerry_blue_terrier', 'n02093991-Irish_terrier', 'n02094114-Norfolk_terrier', 'n02094258-Norwich_terrier', 'n02094433-Yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096294-Australian_terrier', 'n02096437-Dandie_Dinmont', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101388-Brittany_spaniel', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-Old_English_sheepdog', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106166-Border_collie', 'n02106382-Bouvier_des_Flandres', 'n02106550-Rottweiler', 'n02106662-German_shepherd', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02109961-Eskimo_dog', 'n02110063-malamute', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113023-Pembroke', 'n02113186-Cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog']\n"
     ]
    }
   ],
   "source": [
    "# show dataset info\n",
    "print(\"\\ntraing dataset size:\", len(train_ds))\n",
    "print(\"test dataset size:\", len(test_ds))\n",
    "print(\"\\nclass names:\\n\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE_Block(Model):\n",
    "    def __init__(self, filters):\n",
    "        super(SE_Block, self).__init__(name='')\n",
    "\n",
    "        r = 8\n",
    "\n",
    "        self.global_avg_pool = GlobalAveragePooling2D()\n",
    "\n",
    "        self.fc1 = Dense(filters / r, activation='relu')\n",
    "\n",
    "        self.fc2 = Dense(filters, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        c = x.shape[-1]\n",
    "        inp = x\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = tf.reshape(x, [-1, 1, 1, c])\n",
    "        x *= inp\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBasicBlock(Model):\n",
    "    def __init__(self, filters, kernel_size, padding='same', strides=1):\n",
    "        super(ResBasicBlock, self).__init__(name='')\n",
    "\n",
    "        flt1, flt2, flt3 = filters\n",
    "\n",
    "        self.conv1 = Conv2D(flt1, 1, padding=padding, strides=strides)\n",
    "        #             kernel_regularizer=tf.keras.regularizers.l2(l=0.003))\n",
    "\n",
    "        self.covn2 = Conv2D(flt2, kernel_size, padding=padding)\n",
    "\n",
    "        self.conv3 = Conv2D(flt3, 1, padding=padding)\n",
    "        #             kernel_regularizer=tf.keras.regularizers.l2(l=0.003))\n",
    "\n",
    "        self.reshape_conv = Conv2D(flt3, 1, padding=padding, strides=strides)\n",
    "\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.bn4 = BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        inp = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.covn2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        inp = self.reshape_conv(inp)\n",
    "        inp = self.bn4(inp)\n",
    "        x += inp\n",
    "\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockA(Model):\n",
    "    def __init__(self):\n",
    "        super(ResBlockA, self).__init__(name='')\n",
    "\n",
    "        filters = (32, 32, 128)\n",
    "\n",
    "        self.res_blocks = Sequential([])\n",
    "\n",
    "        for _ in range(3):\n",
    "            self.res_blocks.add(ResBasicBlock(filters, kernel_size=3))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockB(Model):\n",
    "    def __init__(self):\n",
    "        super(ResBlockB, self).__init__(name='')\n",
    "\n",
    "        filters = (64, 64, 256)\n",
    "\n",
    "        self.res_blocks = Sequential(\n",
    "            [ResBasicBlock(filters, kernel_size=3, strides=2)])\n",
    "\n",
    "        for _ in range(3):\n",
    "            self.res_blocks.add(ResBasicBlock(filters, kernel_size=3))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockC(Model):\n",
    "    def __init__(self):\n",
    "        super(ResBlockC, self).__init__(name='')\n",
    "\n",
    "        filters = (128, 128, 512)\n",
    "\n",
    "        self.res_blocks = Sequential(\n",
    "            [ResBasicBlock(filters, kernel_size=3, strides=2)])\n",
    "\n",
    "        for _ in range(5):\n",
    "            self.res_blocks.add(ResBasicBlock(filters, kernel_size=3))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockD(Model):\n",
    "    def __init__(self):\n",
    "        super(ResBlockD, self).__init__(name='')\n",
    "\n",
    "        filters = (512, 512, 1024)\n",
    "\n",
    "        self.res_blocks = Sequential(\n",
    "            [ResBasicBlock(filters, kernel_size=3, strides=2)])\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.res_blocks.add(ResBasicBlock(filters, kernel_size=3))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BokuNet(Model):\n",
    "    def __init__(self):\n",
    "        super(BokuNet, self).__init__(name='BokuNet')\n",
    "        self.conv1 = Conv2D(32, 7, strides=2)\n",
    "        self.max_pool = MaxPooling2D((3, 3), strides=2)\n",
    "\n",
    "        self.res_bloack_a = ResBlockA()\n",
    "        self.res_block_b = ResBlockB()\n",
    "        #         self.res_block_c = ResBlockC()\n",
    "        #         self.res_block_d = ResBlockD()\n",
    "\n",
    "        self.avg_pool = AveragePooling2D()\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.out_fc = Dense(120, activation='softmax')\n",
    "\n",
    "\n",
    "#         self.drop1 = Dropout(0.5)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x / 255  # normalization\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        #         print(x.shape)\n",
    "        x = self.max_pool(x)\n",
    "        #         print(x.shape)\n",
    "\n",
    "        x = self.res_bloack_a(x)\n",
    "        #         print('a', x.shape)\n",
    "\n",
    "        x = self.res_block_b(x)\n",
    "        #         print('b', x.shape)\n",
    "\n",
    "        #         x = self.res_block_c(x)\n",
    "        #         print('c', x.shape)\n",
    "\n",
    "        #         x = self.res_block_d(x)\n",
    "        #         print('d', x.shape)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        #         print(x.shape)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.out_fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BokuNet()\n",
    "# # model = SE_Block(64)\n",
    "# imgs_shape = (128, 32, 32, 3)\n",
    "# model.build(imgs_shape)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimiNet(Model):\n",
    "    def __init__(self):\n",
    "        super(KimiNet, self).__init__(name='KimiNet')\n",
    "        self.conv1 = Conv2D(32, 7, strides=2, activation='relu')\n",
    "        self.max_pool1 = MaxPooling2D((3, 3))\n",
    "        #         self.max_pool2 = MaxPooling2D((2, 2))\n",
    "\n",
    "        self.res_basic_block1 = ResBlockA()\n",
    "        self.se_block1 = SE_Block(128)\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.avg_pool1 = AveragePooling2D((2, 2))\n",
    "\n",
    "        self.res_basic_block2 = ResBlockB()\n",
    "        self.se_block2 = SE_Block(256)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.avg_pool2 = AveragePooling2D((2, 2))\n",
    "\n",
    "        self.res_basic_block3 = ResBlockC()\n",
    "\n",
    "        self.gavg_pool = GlobalAveragePooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.out_fc = Dense(120, activation='softmax')\n",
    "\n",
    "        self.drop3 = Dropout(0.25)\n",
    "        self.drop4 = Dropout(0.25)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x / 255.0  # normalization\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.res_basic_block1(x)\n",
    "        x = self.se_block1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.avg_pool1(x)\n",
    "\n",
    "        x = self.res_basic_block2(x)\n",
    "        x = self.se_block2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.avg_pool2(x)\n",
    "\n",
    "        x = self.res_basic_block3(x)\n",
    "\n",
    "        x = self.gavg_pool(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.drop4(x)\n",
    "        x = self.out_fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3),strides=2, input_shape=(150, 150, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "# model.add(AveragePooling2D((1, 1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"KimiNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "res_block_a (ResBlockA)      multiple                  90816     \n",
      "_________________________________________________________________\n",
      "se__block (SE_Block)         multiple                  4240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo multiple                  0         \n",
      "_________________________________________________________________\n",
      "res_block_b (ResBlockB)      multiple                  512512    \n",
      "_________________________________________________________________\n",
      "se__block_1 (SE_Block)       multiple                  16672     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "res_block_c (ResBlockC)      multiple                  3118592   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  61560     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,810,664\n",
      "Trainable params: 3,787,496\n",
      "Non-trainable params: 23,168\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = KimiNet()\n",
    "imgs, labels = next(iter(train_ds))\n",
    "model.build(imgs.shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 4.8354 - accuracy: 0.0157\n",
      "Epoch 00001: val_loss improved from inf to 4.90539, saving model to checkpoint/sdd\\cp.ckpt\n",
      "254/254 [==============================] - 265s 1s/step - loss: 4.8354 - accuracy: 0.0157 - val_loss: 4.9054 - val_accuracy: 0.0078\n",
      "Epoch 2/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 4.4573 - accuracy: 0.0338\n",
      "Epoch 00002: val_loss improved from 4.90539 to 4.55064, saving model to checkpoint/sdd\\cp.ckpt\n",
      "254/254 [==============================] - 125s 494ms/step - loss: 4.4573 - accuracy: 0.0338 - val_loss: 4.5506 - val_accuracy: 0.0349\n",
      "Epoch 3/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 4.2754 - accuracy: 0.0484\n",
      "Epoch 00003: val_loss improved from 4.55064 to 4.27162, saving model to checkpoint/sdd\\cp.ckpt\n",
      "254/254 [==============================] - 125s 493ms/step - loss: 4.2754 - accuracy: 0.0484 - val_loss: 4.2716 - val_accuracy: 0.0485\n",
      "Epoch 4/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 4.1436 - accuracy: 0.0608\n",
      "Epoch 00004: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 125s 491ms/step - loss: 4.1436 - accuracy: 0.0608 - val_loss: 4.4095 - val_accuracy: 0.0495\n",
      "Epoch 5/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 4.0255 - accuracy: 0.0748\n",
      "Epoch 00005: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 126s 495ms/step - loss: 4.0255 - accuracy: 0.0748 - val_loss: 4.8016 - val_accuracy: 0.0285\n",
      "Epoch 6/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.9119 - accuracy: 0.0896\n",
      "Epoch 00006: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 134s 527ms/step - loss: 3.9119 - accuracy: 0.0896 - val_loss: 4.4147 - val_accuracy: 0.0707\n",
      "Epoch 7/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.7979 - accuracy: 0.1047\n",
      "Epoch 00007: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 129s 507ms/step - loss: 3.7979 - accuracy: 0.1047 - val_loss: 5.1784 - val_accuracy: 0.0401\n",
      "Epoch 8/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.6754 - accuracy: 0.1239\n",
      "Epoch 00008: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 127s 501ms/step - loss: 3.6754 - accuracy: 0.1239 - val_loss: 4.6403 - val_accuracy: 0.0456\n",
      "Epoch 9/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.5713 - accuracy: 0.1365\n",
      "Epoch 00009: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 126s 494ms/step - loss: 3.5713 - accuracy: 0.1365 - val_loss: 4.4057 - val_accuracy: 0.0561\n",
      "Epoch 10/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.5178 - accuracy: 0.1445\n",
      "Epoch 00010: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 128s 503ms/step - loss: 3.5178 - accuracy: 0.1445 - val_loss: 5.5848 - val_accuracy: 0.0341\n",
      "Epoch 11/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.3685 - accuracy: 0.1715\n",
      "Epoch 00011: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 128s 506ms/step - loss: 3.3685 - accuracy: 0.1715 - val_loss: 4.3023 - val_accuracy: 0.0874\n",
      "Epoch 12/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.2110 - accuracy: 0.1930\n",
      "Epoch 00012: val_loss did not improve from 4.27162\n",
      "254/254 [==============================] - 127s 500ms/step - loss: 3.2110 - accuracy: 0.1930 - val_loss: 4.3547 - val_accuracy: 0.0795\n",
      "Epoch 13/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 3.0353 - accuracy: 0.2197\n",
      "Epoch 00013: val_loss improved from 4.27162 to 3.90571, saving model to checkpoint/sdd\\cp.ckpt\n",
      "254/254 [==============================] - 126s 498ms/step - loss: 3.0353 - accuracy: 0.2197 - val_loss: 3.9057 - val_accuracy: 0.1179\n",
      "Epoch 14/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 2.8787 - accuracy: 0.2484\n",
      "Epoch 00014: val_loss did not improve from 3.90571\n",
      "254/254 [==============================] - 129s 507ms/step - loss: 2.8787 - accuracy: 0.2484 - val_loss: 4.2313 - val_accuracy: 0.1042\n",
      "Epoch 15/100\n",
      "254/254 [==============================] - ETA: 0s - loss: 2.7281 - accuracy: 0.2790\n",
      "Epoch 00015: val_loss did not improve from 3.90571\n",
      "254/254 [==============================] - 131s 518ms/step - loss: 2.7281 - accuracy: 0.2790 - val_loss: 4.1878 - val_accuracy: 0.1196\n",
      "Epoch 16/100\n",
      "139/254 [===============>..............] - ETA: 48s - loss: 2.6351 - accuracy: 0.2965"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0da25471b02c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                     callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    779\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2814\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2815\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2816\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2818\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1842\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1843\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\root\\pycharmprojects\\bokunet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "checkpoint_path = \"checkpoint/sdd/cp.ckpt\"\n",
    "\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              monitor='val_loss',\n",
    "                              save_weights_only=True,\n",
    "                              save_best_only=True,\n",
    "                              mode='min',\n",
    "                              verbose=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    steps_per_epoch=len(train_ds),\n",
    "                    validation_data=test_ds,\n",
    "                    validation_steps=len(test_ds),\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recreate the exact same model, including its weights and the optimizer\n",
    "# new_model = tf.keras.models.load_model('the_brain.h5')\n",
    "\n",
    "# # Show the model architecture\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs_range = range(EPOCHS)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
